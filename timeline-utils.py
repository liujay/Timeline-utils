"""
    Script to 
        1. create daily CSV/GPX files from Google map Timeline file
        2. create a GPX file from a CSV timeline file
        3. create a CSV file from a GPX timeline file

    Sample Usages: python3 timeline-utils.py export 
                   python3 timeline-utils.py csv2gpx timeline.csv 
                   python3 timeline-utils.py gpx2csv timeline.gpx 

"""

import bisect
import csv
import gpxpy
import gpxpy.gpx
import os
import json
import sys
import typer
from datetime import datetime
from operator import itemgetter
from xml.dom import minidom

app = typer.Typer()

# sematic keys of interest
semantickeys = ['activity', 'timelineMemory', 'timelinePath', 'visit', 'noMatch']

def create_csv_file(points, outfile, headers):
    """
    create csv file from a list of location points

    input: points - a list of location points 
           headers - header of CSV file, eg
                     ['Time', 'Latitude', 'Longitude', 'Tag', 'Info']
    output: outfile, a csv file representing the points list
    """

    # write to CSV file
    with open(outfile, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(headers)     # Write header
        writer.writerows(points)      # Write data rows

def create_gpx_file(points, outfile):
    """
    Create GPX file using gpxpy    
    
    input: points - a list of location points 
                    each entry is a list of one location point containing:
                        ['Time', 'Latitude', 'Longitude', 'Tag', 'Info']
    output: outfile - a gpx file representing the points list
    """
    # Create a new GPX object
    gpx = gpxpy.gpx.GPX()

    # Create a new track
    gpx_track = gpxpy.gpx.GPXTrack()
    gpx.tracks.append(gpx_track)

    # Create a new segment in the track
    gpx_segment = gpxpy.gpx.GPXTrackSegment()
    gpx_track.segments.append(gpx_segment)

    # Add points to segment
    for point in points:
        lat = point[1]
        lon = point[2]
        timestring = point[0]
        gpx_segment.points.append(gpxpy.gpx.GPXTrackPoint(
            latitude=lat, longitude=lon, time=datetime.fromisoformat(timestring)))

    # Generate the GPX XML string
    gpx_xml = gpx.to_xml()
    # Write the XML string to a .gpx file
    with open(outfile, "w") as f:
        f.write(gpx_xml)

def parse_timeline_json(infile):
    """
    process the input timeline json file to build a dictionay of locations

    input: infile - a Timeline json file generated by google map
    output: date_points - a dictornay with keys of date (eg, '2025-06-23') and 
                             values of time and location info ... 
                             (ie, [time, lat, lon, tag, info]) 
    """
    # load input timeline json file
    with open(infile, "r", encoding="utf-8") as f:
        data = json.load(f)

    segments = data["semanticSegments"]
    date_points = {}
    counter = {}
    #
    # process all entries in "semanticSegments" section
    for segidx, seg in enumerate(segments):
        if 'timelinePath' in seg.keys():
            counter['timelinePath'] = counter.get('timelinePath', 0) + 1
            # take all entries in timelinePath
            for index, path_point in enumerate(seg.get("timelinePath", [])):
                try:
                    # Extract and parse data
                    raw_coords = path_point["point"].replace("째", "").strip()
                    coords = raw_coords.split(", ")
                    lat, lon = coords[0], coords[1]
                    time = path_point["time"]
                    tag = f"timelinePath-{index+1}"
                    # Extract date for grouping
                    date = datetime.fromisoformat(time).date().isoformat()
                    # Group by date
                    if date not in date_points:
                        date_points[date] = []
                    date_points[date].append([time, lat, lon, tag])
                except (KeyError, ValueError):
                    continue  # Skip invalid points
        elif 'visit' in seg.keys():
            counter['visit'] = counter.get('visit', 0) + 1
            # take start and end points in visit
            #   coordinates for start and end point are the same in this type
            #   info filled with "semanticType" or "placeId"
            try:
                raw_coords = seg["visit"]["topCandidate"]["placeLocation"]["latLng"].replace("째", "").strip()
                coords = raw_coords.split(", ")
                lat, lon = coords[0], coords[1]
                stype = seg["visit"]["topCandidate"]["semanticType"]
                if stype in ["HOME", "WORK"]:
                    info = stype
                else: 
                    info = f'placeId: {seg["visit"]["topCandidate"]["placeId"]}' 
                startTime = seg["startTime"]
                endTime = seg["endTime"]
                startDate = datetime.fromisoformat(startTime).date().isoformat()
                endDate = datetime.fromisoformat(endTime).date().isoformat()
                date_time = [(startDate, startTime, 'start'), (endDate, endTime, 'end')]
                for _item in date_time:
                    date, time, suffix = _item
                    tag = f"visit-{suffix}"
                    if date not in date_points:
                        date_points[date] = []
                    date_points[date].append([time, lat, lon, tag, info])
            except (KeyError, ValueError):
                continue  # Skip invalid points
        elif 'activity' in seg.keys():
            counter['activity'] = counter.get('activity', 0) + 1
            # take start and end points in activity
            #   coordinates for start and end point are different
            #   info filled with "type"
            try:
                startRaw_coords = seg["activity"]["start"]["latLng"].replace("째", "").strip()
                startCoords = startRaw_coords.split(", ")
                endRaw_coords = seg["activity"]["end"]["latLng"].replace("째", "").strip()
                endCoords = endRaw_coords.split(", ")
                info = seg["activity"]["topCandidate"]["type"]
                startTime = seg["startTime"]
                endTime = seg["endTime"]
                startDate = datetime.fromisoformat(startTime).date().isoformat()
                endDate = datetime.fromisoformat(endTime).date().isoformat()
                # check if overnight activity
                overnight = True if endDate > startDate else False
                # twist date_time_coords list if overnight activity
                #   -- to make start and end points both appearing in endDate's data
                #   ----    by adding one entry to endDate point with startDate
                if overnight: 
                    date_time_coords = [(startDate, startTime, startCoords, 'start'), 
                                        (endDate, startTime, startCoords, 'start'), 
                                        (endDate, endTime, endCoords, 'end')]                    
                else:
                    date_time_coords = [(startDate, startTime, startCoords, 'start'), 
                                        (endDate, endTime, endCoords, 'end')]
                for _item in date_time_coords:
                    date, time, coords, suffix = _item
                    lat, lon = coords[0], coords[1]
                    tag = f"activity-{suffix}"
                    if date not in date_points:
                        date_points[date] = []
                    date_points[date].append([time, lat, lon, tag, info])
            except (KeyError, ValueError):
                continue  # Skip invalid points
        elif 'timelineMemory' in seg.keys():
            counter['timelineMemory'] = counter.get('timelineMemory', 0) + 1
            # skip timelineMemory segments for now
            print(f"--- Skipping segment {segidx} with key 'timelineMemory'")
            pass # for fun
        else:
            counter['noMatch'] = counter.get('noMatch', 0) + 1
            print(f"!!! No matching Semantic in segment: {segidx} !!!")
    
    return date_points, counter

def findgpxindex(headers):
    """
    find the indices (time, latitude, longitude) in csv header list

    input: headers list of the csv file
    output: dictionary of indices for gpx info in csv columns: 
            time, latitude, longitude
    """
    gpxlist = ['time', 'latitude', 'longitude']
    # all headers to lower case
    headers = [h.lower() for h in headers]
    # find indices
    gpxindex = {}
    for item in gpxlist:
        try:
            index = headers.index(item)
        except:
            print(f"'{item}' is not in CSV header: {headers}")
            sys.exit(97)
        gpxindex[item] = index
    return gpxindex

def gettext(nodelist):
    """
    Get the text of a dom element
    """
    value = []
    for node in nodelist:
        if node.nodeType == node.TEXT_NODE:
            value.append(node.data)
    return ''.join(value)

def readcsv(infile: str):
    """
    Read csv file

    input: infile
    output: a list of the location point: [time, latitude, longitude]    
    """
    # check if infile with extention '.csv'
    filename = os.path.basename(os.path.abspath(infile))
    fname, ext = os.path.splitext(filename)
    if ext != '.csv':
        print(f"!!! exiting with code 98 -- Looks like {infile} is not a CSV file !!!")
        sys.exit(98)

    # read the csv file
    with open(infile, 'r', newline='') as f:
        # Create a CSV reader object
        csv_reader = csv.reader(f)
        # Read the header row
        headers = next(csv_reader)
        print(f"Headers of CSV:")
        print(f"    {headers}")
        # Find index of latitude, longitude and time
        hindex = findgpxindex(headers)
        print(f"\nMapping of header:")
        print(f"    latitude:{hindex['latitude']}, longitude:{hindex['longitude']}, time:{hindex['time']}\n")
        # Create points list from CSV data rows
        points = []
        for row in csv_reader:
            lat = row[hindex['latitude']]
            lon = row[hindex['longitude']]
            time = row[hindex['time']]
            points.append([time, lat, lon])

    return points

@app.command()
def gpx2csv(infile: str, csvdir: str='__GPX2CSV'):
    """
    Create/Convert a timeline GPX file to CSV file

    input: infile
    output: csv file in the name of infile    
    """
    # check if infile with extention '.csv'
    dirname = os.path.dirname(os.path.abspath(infile))
    filename = os.path.basename(os.path.abspath(infile))
    fname, ext = os.path.splitext(filename)
    if ext != '.gpx':
        print(f"!!! exiting with code 98 -- Looks like {infile} is not a GPX file !!!")
        sys.exit(98)

    # setup output
    outdir = f"{dirname}/{csvdir}"      
    os.makedirs(outdir, exist_ok=True)
    outfile = f"{outdir}/{fname}.csv"

    # CSV file header
    headers = ["Time", "Latitude", "Longitude"]

    # read and process GPX file
    gpxdom = minidom.parse(infile)
    trkpt = gpxdom.getElementsByTagName("trkpt")
    points = []
    # parse trackpoint elements
    for point in trkpt:
        # lat and lng are attributes
        lat = point.attributes["lat"].value
        lng = point.attributes["lon"].value
        # look for time, which 
        #   should be the only element tagged with 'time'
        #   so, here is it
        telement = point.getElementsByTagName("time")[0]
        time = gettext(telement.childNodes)
        row = [time, lat, lng]
        points.append(row)
    
    # create csv
    create_csv_file(points, outfile, headers)
    print(f"Created {outfile}")

@app.command()
def csv2gpx(infile: str, gpxdir: str='__CSV2GPX'):
    """
    Create/Convert a timeline CSV file to GPX file

    input: infile
    output: gpx file in the name of infile
    """
    # check if infile with extention '.csv'
    dirname = os.path.dirname(os.path.abspath(infile))
    filename = os.path.basename(os.path.abspath(infile))
    fname, ext = os.path.splitext(filename)
    if ext != '.csv':
        print(f"!!! exiting with code 98 -- Looks like {infile} is not a CSV file !!!")
        sys.exit(98)

    # setup output
    outdir = f"{dirname}/{gpxdir}"      
    os.makedirs(outdir, exist_ok=True)
    outfile = f"{outdir}/{fname}.gpx"
    with open(infile, 'r', newline='') as f:
        # Create a CSV reader object
        csv_reader = csv.reader(f)
        # Read the header row
        headers = next(csv_reader)
        print(f"Headers of CSV:")
        print(f"    {headers}")
        # Find index of latitude, longitude and time
        hindex = findgpxindex(headers)
        print(f"\nMapping of header:")
        print(f"    latitude:{hindex['latitude']}, longitude:{hindex['longitude']}, time:{hindex['time']}\n")
        # Create points list from CSV data rows
        points = []
        for row in csv_reader:
            lat = row[hindex['latitude']]
            lon = row[hindex['longitude']]
            time = row[hindex['time']]
            points.append([time, lat, lon])
        # Create GPX file from points
        create_gpx_file(points, outfile)
        print(f"Created {outfile}")

@app.command()
def search_csv(time: str, infile: str):
    """
    Search closest time in CSV file/folder

    input: time - timestamp to search
           infile - name of to search file
    output: a list of 2 points

    """

    ts = datetime.fromisoformat(time)
    points = readcsv(infile)
    idx = bisect.bisect_left([datetime.fromisoformat(item[0]) for item in points], ts)

    # find the elements around the insertion point
    matches = []
    if idx > 0:
        matches.append(points[idx - 1])
    if idx < len(points):
        matches.append(points[idx])

    # determine the truly closest match
    if len(matches) == 1:
        best = 0
        second = None
    elif len(matches) == 2:
        diff1 = abs((datetime.fromisoformat(matches[0][0]) - ts).total_seconds())
        diff2 = abs((datetime.fromisoformat(matches[1][0]) - ts).total_seconds())
        best = 0 if diff1 < diff2 else 1
        second = 1 if diff1 < diff2 else 0
    else:
        best = second = None

    # output
    if best != None:
        print(f"\nBest match for {time} is {matches[best]}\n")
    if second != None:
        print(f"\n2nd best match for {time} is {matches[second]}\n")
    if best == None and second == None:
        print(f"\n!!! Something went wrong in search for {time} in file {infile} !!!\n")

@app.command()
def export(infile: str='Timeline.json', csv: bool=True, gpx: bool=True,
                      csvdir: str='_CSV_Output', gpxdir: str='_GPX_Output'):
    """
    Export/Convert timeline json file to CSV/GPX files

    input: infile -- timeline json file generated by google map
    output: daily csv/gpx files in seperate (csvdir/gpxdir) folders
    """

    # ensure infile exits
    if not os.path.exists(infile):
        print(f"Input file {infile} not found")
        sys.exit(99)
    # ensure the output directory exists
    dirname = os.path.dirname(os.path.abspath(infile))
    if csv:
        csvdir = f"{dirname}/{csvdir}"
        os.makedirs(csvdir, exist_ok=True)
    if gpx:
        gpxdir = f"{dirname}/{gpxdir}"
        os.makedirs(gpxdir, exist_ok=True)
    
    # process infile and build date based time-location dictionary 
    date_points, counter = parse_timeline_json(infile)

    # export to specified file formats
    for date, points in date_points.items():
        # sort points list first
        #   sort by key 'time' that lives in [0]
        points.sort(key=itemgetter(0))
        # Convert date format to dd-mm-yyyy
        formatted_date = datetime.strptime(date, "%Y-%m-%d").strftime("%Y-%m-%d")
        # export to different formats
        if csv:
            # setup headers for csv file
            headers = ['Time', 'Latitude', 'Longitude', 'Tag', 'Info']
            csvfile = os.path.join(csvdir, f"{formatted_date}.csv")
            create_csv_file(points, csvfile, headers)
            print(f"Created: {csvfile}")
        if gpx:
            gpxfile = os.path.join(gpxdir, f"{formatted_date}.gpx")
            create_gpx_file(points, gpxfile)
            print(f"Created: {gpxfile}")

    # print some stats on timeline files
    # segment stats
    total = 0
    print()
    print(f"---------------------------------------------")
    print(f"a breakdown of semantic segments in timeline file: {infile}")
    for k in semantickeys:
        count = counter.get(k, 0)
        total += count
        print(f"    {k}: {count}")
    print(f"---------------------------------------------")
    print(f"    Total: {total} segments")    
if __name__ == "__main__":
    app()